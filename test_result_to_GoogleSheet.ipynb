{"cells":[{"cell_type":"markdown","source":["#Запуск алгоритма"],"metadata":{"id":"Is_hIasg3ndy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fOvjJz6E0Pj0","cellView":"form"},"outputs":[],"source":["#@title Установка пакетов\n","!pip  install langchain==0.0.335 openai==1.2.3 tiktoken==0.5.1 pydantic==1.10.8 faiss-cpu==1.7.4 nltk oauth2client >/dev/null\n","!pip install gspread"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ADZL3ATj0dOY","cellView":"form","executionInfo":{"status":"ok","timestamp":1701947415464,"user_tz":-180,"elapsed":1697,"user":{"displayName":"Вероника Жидяевская","userId":"08359914054878967108"}}},"outputs":[],"source":["#@title Импорт библиотек\n","\n","import os\n","import getpass\n","import requests\n","\n","from langchain.embeddings.openai import OpenAIEmbeddings\n","from langchain.text_splitter import CharacterTextSplitter\n","from langchain.text_splitter import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n","from langchain.vectorstores import FAISS\n","from langchain.document_loaders import TextLoader\n","import openai\n","from openai import OpenAI\n","import tiktoken\n","import re\n","import requests\n","from langchain.docstore.document import Document\n","\n","import pandas as pd\n","from google.oauth2.service_account import Credentials\n","\n","from oauth2client.service_account import ServiceAccountCredentials\n","import gspread\n","import json\n","import numpy as np\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"brwhPXP0Ds8B","cellView":"form","executionInfo":{"status":"ok","timestamp":1701947415465,"user_tz":-180,"elapsed":17,"user":{"displayName":"Вероника Жидяевская","userId":"08359914054878967108"}}},"outputs":[],"source":["#@title Опредение функций\n","\n","def load_text_from_github(kdb_link):\n","## правильная ссылка: https://github.com/terrainternship/GPT_LaserLove/raw/main/instruction_1.txt\n","## неправильная ссылка:  https://github.com/terrainternship/GPT_LaserLove/blob/main/instruction_1.txt\n","  response = requests.get(kdb_link)\n","  txt = response.text\n","  return txt\n","\n","def load_googledoc_by_url(doc_url) -> str: # Функция load_googledoc_by_url предназначена для загрузки текста из гуглдока, по ссылке (doc_url)\n","  # Extract the document ID from the URL\n","  match_ = re.search('/document/d/([a-zA-Z0-9-_]+)', doc_url)\n","  if match_ is None:\n","    raise ValueError('Invalid Google Docs URL')\n","  doc_id = match_.group(1)\n","\n","  # Download the document as plain text\n","  response = requests.get(f'https://docs.google.com/document/d/{doc_id}/export?format=txt')\n","  response.raise_for_status()\n","  return response.text\n","\n","def load_document_text(file_path) -> str:   # Функция load_document_text предназначена для загрузки текста из файла, расположенного по указанному пути (file_path)\n","#    with open(file_path, 'r', encoding='windows-1251') as file:\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        text = file.read()\n","    text_encoded = text.encode('utf-8')\n","    text = text_encoded.decode('utf-8')\n","    return text\n","\n","def load_text(any_link):\n","  if len(any_link)==0:\n","    text=''\n","  else:\n","    if \"github.com\" in any_link:\n","      if \"blob\" in any_link: any_link=any_link.replace(\"blob\", \"raw\")\n","      text = load_text_from_github(any_link)\n","    elif \"docs.google.com\" in any_link:\n","      text = load_googledoc_by_url(any_link)\n","    else:\n","      text = load_document_text(any_link)\n","    return text\n","\n","\n","def num_tokens_from_string(string: str, encoding_name: str) -> int:\n","      \"\"\"Возвращает количество токенов в строке\"\"\"\n","      encoding = tiktoken.get_encoding(encoding_name)\n","      num_tokens = len(encoding.encode(string))\n","      return num_tokens\n","\n","def split_text(text, max_count, chunk_overlap, verbose=0, double_split=1):\n","    # Функция для подсчета количества токенов в фрагменте\n","    def num_tokens(fragment):\n","        return num_tokens_from_string(fragment, \"cl100k_base\")\n","\n","    headers_to_split_on = [\n","    (\"#\", \"Header 1\"),\n","    (\"##\", \"Header 2\"),\n","    (\"###\", \"Header 3\"),\n","                          ]\n","    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n","    fragments = markdown_splitter.split_text(text)\n","\n","    # Создание объекта разделителя текста\n","    splitter = RecursiveCharacterTextSplitter(chunk_size=max_count, chunk_overlap=chunk_overlap, length_function=num_tokens)\n","\n","    # Список для хранения фрагментов текста\n","    source_chunks = []\n","\n","    # Обработка каждого фрагмента текста\n","    for fragment in fragments:\n","\n","        if verbose:\n","            # Вывод количества слов/токенов в фрагменте, если включен режим verbose\n","            count = num_tokens(fragment.page_content)\n","            print(f\"Tokens in text fragment = {count}\\n{'-' * 5}\\n{fragment.page_content}\\n{'=' * 20}\")\n","        if double_split:\n","          # Разбиение фрагмента текста на части заданной длины с помощью разделителя\n","          # и добавление каждой части в список source_chunks  и передача в чанк метадата из маркдауновскго сплиттера\n","          source_chunks.extend(Document(page_content=chunk, metadata=fragment.metadata) for chunk in splitter.split_text(fragment.page_content))\n","        else:\n","          source_chunks = fragments\n","\n","    # Возвращение списка фрагментов текста\n","    return source_chunks\n","\n","def create_search_index(data, chunk_size, chunk_overlap, verbo, double_split):\n","    source_chunks = []\n","    source_chunks = split_text(text=data, max_count=chunk_size, chunk_overlap=chunk_overlap, verbose=verbo, double_split=double_split)\n","    return FAISS.from_documents(source_chunks, OpenAIEmbeddings())\n","\n","def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\"):\n","    \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n","    try:\n","        encoding = tiktoken.encoding_for_model(model)\n","    except KeyError:\n","        encoding = tiktoken.get_encoding(\"cl100k_base\")\n","    if model == \"gpt-3.5-turbo-0301\":  # note: future models may deviate from this\n","        num_tokens = 0\n","        for message in messages:\n","            num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n","            for key, value in message.items():\n","                num_tokens += len(encoding.encode(value))\n","                if key == \"name\":  # if there's a name, the role is omitted\n","                    num_tokens += -1  # role is always required and always 1 token\n","        num_tokens += 2  # every reply is primed with <im_start> assistant\n","        return num_tokens\n","    else:\n","        raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not presently implemented for model {model}.\"\"\")\n","\n","def answer_user_question(system_doc_text, knowledge_base_url, topic, instructions, temperature, verbose, k, chunk_size, chunk_overlap, model, double_split):\n","    if \"github.com\" in knowledge_base_url:\n","      knowledge_base_text = load_text_from_github(knowledge_base_url)\n","    elif \"docs.google.com\" in knowledge_base_url:\n","      knowledge_base_text = load_googledoc_by_url(knowledge_base_url)\n","    else:\n","      knowledge_base_text = load_document_text(knowledge_base_url)\n","\n","    knowledge_base_index = create_search_index(knowledge_base_text, chunk_size, chunk_overlap, verbose, double_split)\n","    return answer_index(system_doc_text, topic, instructions, knowledge_base_index, temperature, verbose, k, model)\n","\n","\n","def answer_index(system, topic, instructions, search_index, temp, verbose, k, model):\n","    docs = search_index.similarity_search_with_score(topic, k=k)\n","    message_content = '\\n '.join([f'Отрывок текста №{i+1}\\n{doc[0].page_content}' for i, doc in enumerate(docs)])\n","    messages = [{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": f\"{instructions}\\n\\nТексты для анализа:\\n{message_content}\\n\\nОбращение клиента: {topic}\"}]\n","\n","    completion = openai.chat.completions.create(model=model, messages=messages, temperature=temp)\n","    return message_content, completion.choices[0].message.content\n"]},{"cell_type":"markdown","source":["#Получение ключа API"],"metadata":{"id":"OaNpbi6LuI1I"}},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4898,"status":"ok","timestamp":1701947420347,"user":{"displayName":"Вероника Жидяевская","userId":"08359914054878967108"},"user_tz":-180},"id":"uaZPhq6d0qm6","outputId":"da0dfeed-bab0-4c19-edc0-701044f80ee3","cellView":"form"},"outputs":[{"name":"stdout","output_type":"stream","text":["OpenAI API Key:··········\n"]}],"source":["#@title Получение ключа API от пользователя и установка его как переменной окружения\n","openai_key = getpass.getpass(\"OpenAI API Key:\")\n","os.environ[\"OPENAI_API_KEY\"] = openai_key\n","openai.api_key = openai_key"]},{"cell_type":"markdown","source":["# Тест моделей"],"metadata":{"id":"Y0r-OzvZK49k"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8859,"status":"ok","timestamp":1701898862342,"user":{"displayName":"Вероника Жидяевская","userId":"08359914054878967108"},"user_tz":-180},"outputId":"f349c1a4-0689-4572-e030-c663758c5ab7","cellView":"form","id":"wrnf5rsV6bo0"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Ответ:\n"," Извините, я не могу предоставить информацию о составе продукции. Однако, если вас интересует косметика с эффектом лифтинга, я могу предложить вам ознакомиться с нашим ассортиментом косметических средств. Вы можете узнать больше о наших продуктах и их ценах, нажав на кнопку \"Хочу узнать цены на косметику\" в меню.\n"]}],"source":["#@title 1. Тест по вопросам к БЗ - вопрос задаем вручную\n","model = \"gpt-3.5-turbo-1106\" #@param [\"gpt-3.5-turbo\", \"gpt-3.5-turbo-16k\", \"gpt-3.5-turbo-1106\"]\n","knowledge_base_link = \"https://github.com/terrainternship/GPT_LaserLove/blob/main/knowledge.md?raw=true\" #@param {type:\"string\"}\n","#chunk_size = 1000 #@param {type: \"slider\", min: 200, max: 1024, step:8}\n","#chunk_overlap = 0 #@param {type: \"slider\", min: 0, max: 256, step:8}\n","temperature = 0.4 #@param {type: \"slider\", min: 0, max: 1, step:0.1}\n","num_fragment = 5 #@param {type:\"integer\"}\n","verbose = \"0\" #@param [0,1]\n","system_prompt_link= \"https://github.com/terrainternship/GPT_LaserLove/raw/main/%D0%9F%D0%A0%D0%9E%D0%9C%D0%A2%20LaserLove%20Svetl.txt\" #@param {type:\"string\"}\n","instructions_link = \"\" #@param {type:\"string\"}\n","Вопрос_клиента = \"\\u041A\\u0430\\u043A\\u043E\\u0439 \\u0441\\u043E\\u0441\\u0442\\u0430\\u0432 \\u0443 \\u043C\\u043E\\u043B\\u043E\\u0447\\u043A\\u0430 \\u0441 \\u044D\\u0444\\u0444\\u0435\\u043A\\u0442\\u043E\\u043C \\u043B\\u0438\\u0444\\u0442\\u0438\\u043D\\u0433\\u0430?\" #@param {type:\"string\"}\n","#content_base = load_googledoc_by_url(kb_url)\n","\n","system_prompt = load_text(system_prompt_link)\n","instructions = load_text(instructions_link)\n","\n","chunks, output1 = answer_user_question(system_prompt, knowledge_base_link, Вопрос_клиента,\n","                               instructions, temperature, int(verbose), num_fragment,\n","                               chunk_size, chunk_overlap, model, double_split=0) #ОБЩИЙ\n","\n","print(\"\\nОтвет:\\n\", output1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YMxo58Z1Hlyy"},"outputs":[],"source":["#@title 2. Тест по вопросам к БЗ групповой по вопросам из Гугл таблицы\n","model = \"gpt-3.5-turbo-1106\" #@param [\"gpt-3.5-turbo\", \"gpt-3.5-turbo-16k\", \"gpt-3.5-turbo-1106\"]\n","knowledge_base_link = \"https://github.com/terrainternship/GPT_LaserLove/blob/main/knowledge.md?raw=true\" #@param {type:\"string\"}\n","#chunk_size = 200 #@param {type: \"slider\", min: 200, max: 1024, step:8}\n","#chunk_overlap = 0 #@param {type: \"slider\", min: 0, max: 256, step:8}\n","temperature = 0.4 #@param {type: \"slider\", min: 0, max: 1, step:0.1}\n","num_fragment = 3 #@param {type:\"integer\"}\n","#verbose = \"0\" #@param [0,1]\n","system_prompt_link= \"\" #@param {type:\"string\"}\n","instructions_link = \"\" #@param {type:\"string\"}\n","GoogleAPI_path = \"\" #@param {type:\"string\"}\n","googlesheet_url = \"https://docs.google.com/spreadsheets/d/1ec4f2uwDPs84jzwnVsBDiOus2-UGTO5gnqcc-UCAMGM\" #@param {type:\"string\"}\n","sheet_name = \"\" #@param {type:\"string\"}\n","первая_строка = 2 #@param {type:\"integer\"}\n","последняя_строка = 96 #@param {type:\"integer\"}\n","\n","input_column_letter = \"B\" #@param {type:\"string\"}\n","output_column_letter = \"J\" #@param {type:\"string\"}\n","chunk_column_letter = \"N\" #@param {type:\"string\"}\n","\n","system_prompt = load_text(system_prompt_link)\n","instructions = load_text(instructions_link)\n","\n","# авторизуемся по токену гугла\n","credentials = Credentials.from_service_account_file(GoogleAPI_path, scopes=['https://spreadsheets.google.com/feeds'])\n","client = gspread.authorize(credentials)\n","\n","# открываем таблицу по URL\n","spreadsheet = client.open_by_url(googlesheet_url)\n","# Выбираем лист по имени\n","worksheet = spreadsheet.worksheet(sheet_name)\n","\n","# Получаем все вопросы из столбца input_column_letter\n","data_values = worksheet.get_all_values()[первая_строка-1:]\n","questions = [row[gspread.utils.a1_to_rowcol(input_column_letter + \"1\")[1] - 1] for row in data_values]\n","\n","for i, question in enumerate(questions, start=2):\n","    if i > последняя_строка:\n","      break\n","    if not isinstance(question, str):\n","      # Пропустить, если question не является строкой\n","      continue\n","    message_chunk, output1 = answer_user_question(system_prompt, knowledge_base_link, question,\n","                                   instructions, temperature, int(verbose), num_fragment,\n","                                   chunk_size, chunk_overlap, model, double_split=0)\n","\n","    # Записываем результат\n","    worksheet.update_cell(i, gspread.utils.a1_to_rowcol(output_column_letter + str(i))[1], output1)\n","    worksheet.update_cell(i, gspread.utils.a1_to_rowcol(chunk_column_letter + str(i))[1], message_chunk)\n","\n","print(\"Данные успешно обработаны и записаны на лист.\")\n"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPjWYRq2CK50vLXe7cV1Eew"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}